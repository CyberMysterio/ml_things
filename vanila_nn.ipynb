{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vanila_nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gmihaila/toy_models/blob/master/vanila_nn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "17LH2G9SZxgF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vanila Neural Network\n",
        "\n",
        "### Simple implementation to play around and modify\n",
        "\n",
        "by GeorgeM."
      ]
    },
    {
      "metadata": {
        "id": "Jgf-S2NfZnbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "305f8632-f8ec-4bfd-c5c2-e61715c3a0a5"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-25 22:24:45--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.32.133\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.32.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23278 (23K) [text/plain]\n",
            "Saving to: ‘pima-indians-diabetes.data.csv’\n",
            "\n",
            "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2018-05-25 22:24:45 (1.60 MB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2efyUH6RfM19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1989
        },
        "outputId": "f8f52012-5cd7-4a36-ca3e-f3430ee2ab3a"
      },
      "cell_type": "code",
      "source": [
        "# Install pydot\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 18298 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.11.94-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.11.94-0ubuntu2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../01-libjbig0_2.1-3.1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../04-libtiff5_4.0.8-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../05-libwebp6_0.6.0-3_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.0-3) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../06-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../07-libgd3_2.2.5-3_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-3) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../08-libpixman-1-0_0.34.0-1_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-1) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../09-libxcb-render0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../10-libxcb-shm0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../11-libcairo2_1.14.10-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.14.10-1ubuntu1) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../12-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../13-libthai-data_0.1.26-3_all.deb ...\n",
            "Unpacking libthai-data (0.1.26-3) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../14-libdatrie1_0.2.10-5_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-5) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../15-libthai0_0.1.26-3_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.26-3) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../16-libpango-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libgraphite2-3:amd64.\n",
            "Preparing to unpack .../17-libgraphite2-3_1.3.10-2_amd64.deb ...\n",
            "Unpacking libgraphite2-3:amd64 (1.3.10-2) ...\n",
            "Selecting previously unselected package libharfbuzz0b:amd64.\n",
            "Preparing to unpack .../18-libharfbuzz0b_1.4.2-1_amd64.deb ...\n",
            "Unpacking libharfbuzz0b:amd64 (1.4.2-1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../24-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../25-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../26-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../27-graphviz_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking graphviz (2.38.0-16ubuntu2) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up libpathplan4 (2.38.0-16ubuntu2) ...\n",
            "Setting up libxcb-render0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-5) ...\n",
            "Setting up libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\n",
            "Setting up libgraphite2-3:amd64 (1.3.10-2) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libxcb-shm0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Setting up libthai-data (0.1.26-3) ...\n",
            "Setting up libcdt5 (2.38.0-16ubuntu2) ...\n",
            "Setting up fontconfig (2.11.94-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.38.0-16ubuntu2) ...\n",
            "Setting up libwebp6:amd64 (0.6.0-3) ...\n",
            "Setting up libcairo2:amd64 (1.14.10-1ubuntu1) ...\n",
            "Setting up libgvpr2 (2.38.0-16ubuntu2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-3) ...\n",
            "Setting up libharfbuzz0b:amd64 (1.4.2-1) ...\n",
            "Setting up libthai0:amd64 (0.1.26-3) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libgvc6 (2.38.0-16ubuntu2) ...\n",
            "Setting up graphviz (2.38.0-16ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FKChHKmWZ3hO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "665cdf66-2a37-40fd-bc78-999b0456e4dd"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from IPython.display import Image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MuPFye1YaGsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d734bebe-e34d-4e13-a861-fc18181cd6dc"
      },
      "cell_type": "code",
      "source": [
        "# Parse data\n",
        "path_file = 'pima-indians-diabetes.data.csv'\n",
        "\n",
        "df = pd.read_csv(path_file, header=None)\n",
        "data = np.array(df.values, dtype=float)\n",
        "\n",
        "x = data[:,:8]  # fist 8 columns\n",
        "y = data[:,8]   # last column\n",
        "\n",
        "print('x shape: ',x.shape)\n",
        "print('y shape: ',y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('x shape: ', (768, 8))\n",
            "('y shape: ', (768,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2vPnufPLay7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build model\n",
        "\n",
        "n_input = 8  # number of inputs\n",
        "n_output = 1 # number of outputs\n",
        "\n",
        "# build each layer\n",
        "model_input = Input(shape=(n_input,), name='INPUT')\n",
        "model_layer1 = Dense(units=8, activation='relu', name='DENSE1')(model_input)\n",
        "model_output = Dense(units=1, activation='sigmoid', name='OUTPUT')(model_layer1)\n",
        "# assemble model\n",
        "model = Model([model_input], model_output)\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0a8XLsAxepwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "667b3d4d-8b4e-4e98-b13d-7335165952fa"
      },
      "cell_type": "code",
      "source": [
        "# image model\n",
        "plot_model(model, to_file='model.png')\n",
        "Image('model.png')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANkAAAD/CAYAAAB8S3NdAAAABmJLR0QA/wD/AP+gvaeTAAAf40lE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\nAbR/InrGWI/8P+9wSOxY0USvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ZFDsNC8xgBlg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5154
        },
        "outputId": "5a9a55e8-fe6b-47d0-ff4f-a7a2033878c3"
      },
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "model.fit(x, y, epochs=150, batch_size=10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "768/768 [==============================] - 0s 316us/step - loss: 2.9456 - acc: 0.6263\n",
            "Epoch 2/150\n",
            "768/768 [==============================] - 0s 166us/step - loss: 2.1683 - acc: 0.6341\n",
            "Epoch 3/150\n",
            "768/768 [==============================] - 0s 171us/step - loss: 1.9201 - acc: 0.6484\n",
            "Epoch 4/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 1.7737 - acc: 0.6523\n",
            "Epoch 5/150\n",
            "768/768 [==============================] - 0s 162us/step - loss: 1.6268 - acc: 0.6497\n",
            "Epoch 6/150\n",
            "768/768 [==============================] - 0s 174us/step - loss: 1.5711 - acc: 0.6497\n",
            "Epoch 7/150\n",
            "768/768 [==============================] - 0s 161us/step - loss: 1.4742 - acc: 0.6510\n",
            "Epoch 8/150\n",
            "768/768 [==============================] - 0s 165us/step - loss: 1.3810 - acc: 0.6693\n",
            "Epoch 9/150\n",
            "768/768 [==============================] - 0s 179us/step - loss: 1.3281 - acc: 0.6706\n",
            "Epoch 10/150\n",
            "768/768 [==============================] - 0s 165us/step - loss: 1.1873 - acc: 0.6836\n",
            "Epoch 11/150\n",
            "768/768 [==============================] - 0s 159us/step - loss: 1.1031 - acc: 0.6849\n",
            "Epoch 12/150\n",
            "768/768 [==============================] - 0s 158us/step - loss: 1.0288 - acc: 0.6927\n",
            "Epoch 13/150\n",
            "768/768 [==============================] - 0s 162us/step - loss: 0.9475 - acc: 0.6875\n",
            "Epoch 14/150\n",
            "768/768 [==============================] - 0s 162us/step - loss: 0.8856 - acc: 0.6771\n",
            "Epoch 15/150\n",
            "768/768 [==============================] - 0s 157us/step - loss: 0.8231 - acc: 0.6862\n",
            "Epoch 16/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.7760 - acc: 0.6758\n",
            "Epoch 17/150\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.7355 - acc: 0.6732\n",
            "Epoch 18/150\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.7061 - acc: 0.6966\n",
            "Epoch 19/150\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.6767 - acc: 0.6706\n",
            "Epoch 20/150\n",
            "768/768 [==============================] - 0s 149us/step - loss: 0.7129 - acc: 0.6549\n",
            "Epoch 21/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.6585 - acc: 0.6901\n",
            "Epoch 22/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.6488 - acc: 0.6979\n",
            "Epoch 23/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.6398 - acc: 0.6979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/150\n",
            "768/768 [==============================] - 0s 155us/step - loss: 0.6467 - acc: 0.7096\n",
            "Epoch 25/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.6385 - acc: 0.6966\n",
            "Epoch 26/150\n",
            "768/768 [==============================] - 0s 152us/step - loss: 0.6620 - acc: 0.6888\n",
            "Epoch 27/150\n",
            "768/768 [==============================] - 0s 156us/step - loss: 0.6387 - acc: 0.6979\n",
            "Epoch 28/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.6854 - acc: 0.6823\n",
            "Epoch 29/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.6376 - acc: 0.6836\n",
            "Epoch 30/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.6241 - acc: 0.6875\n",
            "Epoch 31/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.6263 - acc: 0.6966\n",
            "Epoch 32/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.6375 - acc: 0.7018\n",
            "Epoch 33/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.6359 - acc: 0.6953\n",
            "Epoch 34/150\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.6023 - acc: 0.7057\n",
            "Epoch 35/150\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.6097 - acc: 0.7083\n",
            "Epoch 36/150\n",
            "768/768 [==============================] - 0s 159us/step - loss: 0.6057 - acc: 0.7174\n",
            "Epoch 37/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.6049 - acc: 0.7135\n",
            "Epoch 38/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.6109 - acc: 0.7005\n",
            "Epoch 39/150\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.6194 - acc: 0.7109\n",
            "Epoch 40/150\n",
            "768/768 [==============================] - 0s 152us/step - loss: 0.6174 - acc: 0.7240\n",
            "Epoch 41/150\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.6252 - acc: 0.7096\n",
            "Epoch 42/150\n",
            "768/768 [==============================] - 0s 145us/step - loss: 0.6285 - acc: 0.6992\n",
            "Epoch 43/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.6205 - acc: 0.7031\n",
            "Epoch 44/150\n",
            "768/768 [==============================] - 0s 153us/step - loss: 0.6058 - acc: 0.7109\n",
            "Epoch 45/150\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.6305 - acc: 0.6979\n",
            "Epoch 46/150\n",
            "360/768 [=============>................] - ETA: 0s - loss: 0.6294 - acc: 0.7194"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 140us/step - loss: 0.6166 - acc: 0.7018\n",
            "Epoch 47/150\n",
            "768/768 [==============================] - 0s 140us/step - loss: 0.6380 - acc: 0.6914\n",
            "Epoch 48/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.5786 - acc: 0.7227\n",
            "Epoch 49/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.6137 - acc: 0.7148\n",
            "Epoch 50/150\n",
            "768/768 [==============================] - 0s 146us/step - loss: 0.6160 - acc: 0.6979\n",
            "Epoch 51/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.5935 - acc: 0.7187\n",
            "Epoch 52/150\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.5953 - acc: 0.7266\n",
            "Epoch 53/150\n",
            "768/768 [==============================] - 0s 158us/step - loss: 0.6131 - acc: 0.7201\n",
            "Epoch 54/150\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.6083 - acc: 0.6940\n",
            "Epoch 55/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.5981 - acc: 0.7083\n",
            "Epoch 56/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.6181 - acc: 0.7070\n",
            "Epoch 57/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.6081 - acc: 0.7044\n",
            "Epoch 58/150\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.5877 - acc: 0.7174\n",
            "Epoch 59/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.6218 - acc: 0.7135\n",
            "Epoch 60/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5789 - acc: 0.7318\n",
            "Epoch 61/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5954 - acc: 0.7083\n",
            "Epoch 62/150\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.5681 - acc: 0.7188\n",
            "Epoch 63/150\n",
            "768/768 [==============================] - 0s 139us/step - loss: 0.5852 - acc: 0.7344\n",
            "Epoch 64/150\n",
            "768/768 [==============================] - 0s 152us/step - loss: 0.5858 - acc: 0.7201\n",
            "Epoch 65/150\n",
            "768/768 [==============================] - 0s 153us/step - loss: 0.5829 - acc: 0.7292\n",
            "Epoch 66/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.5774 - acc: 0.7305\n",
            "Epoch 67/150\n",
            "768/768 [==============================] - 0s 149us/step - loss: 0.5727 - acc: 0.7161\n",
            "Epoch 68/150\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.5841 - acc: 0.7201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 69/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.5730 - acc: 0.7253\n",
            "Epoch 70/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5633 - acc: 0.7266\n",
            "Epoch 71/150\n",
            "768/768 [==============================] - 0s 158us/step - loss: 0.6082 - acc: 0.7214\n",
            "Epoch 72/150\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.5753 - acc: 0.7083\n",
            "Epoch 73/150\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.6068 - acc: 0.7201\n",
            "Epoch 74/150\n",
            "768/768 [==============================] - 0s 149us/step - loss: 0.6167 - acc: 0.7044\n",
            "Epoch 75/150\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.5721 - acc: 0.7253\n",
            "Epoch 76/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.5655 - acc: 0.7305\n",
            "Epoch 77/150\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.5730 - acc: 0.7357\n",
            "Epoch 78/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.5907 - acc: 0.6966\n",
            "Epoch 79/150\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.5760 - acc: 0.7201\n",
            "Epoch 80/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5766 - acc: 0.7227\n",
            "Epoch 81/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5867 - acc: 0.7214\n",
            "Epoch 82/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5747 - acc: 0.7227\n",
            "Epoch 83/150\n",
            "768/768 [==============================] - 0s 142us/step - loss: 0.5670 - acc: 0.7253\n",
            "Epoch 84/150\n",
            "768/768 [==============================] - 0s 140us/step - loss: 0.5737 - acc: 0.7227\n",
            "Epoch 85/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.5524 - acc: 0.7318\n",
            "Epoch 86/150\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.5671 - acc: 0.7096\n",
            "Epoch 87/150\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.5831 - acc: 0.7161\n",
            "Epoch 88/150\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.5820 - acc: 0.7122\n",
            "Epoch 89/150\n",
            "768/768 [==============================] - 0s 157us/step - loss: 0.5699 - acc: 0.7318\n",
            "Epoch 90/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5788 - acc: 0.7148\n",
            "Epoch 91/150\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.5584 - acc: 0.7253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 92/150\n",
            "768/768 [==============================] - 0s 155us/step - loss: 0.5618 - acc: 0.7383\n",
            "Epoch 93/150\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.5766 - acc: 0.7096\n",
            "Epoch 94/150\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.5682 - acc: 0.7279\n",
            "Epoch 95/150\n",
            "768/768 [==============================] - 0s 140us/step - loss: 0.5542 - acc: 0.7305\n",
            "Epoch 96/150\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.5684 - acc: 0.7370\n",
            "Epoch 97/150\n",
            "768/768 [==============================] - 0s 153us/step - loss: 0.5801 - acc: 0.7305\n",
            "Epoch 98/150\n",
            "768/768 [==============================] - 0s 161us/step - loss: 0.5529 - acc: 0.7435\n",
            "Epoch 99/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.5604 - acc: 0.7318\n",
            "Epoch 100/150\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.5369 - acc: 0.7253\n",
            "Epoch 101/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5561 - acc: 0.7214\n",
            "Epoch 102/150\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.5613 - acc: 0.7292\n",
            "Epoch 103/150\n",
            "768/768 [==============================] - 0s 152us/step - loss: 0.5516 - acc: 0.7279\n",
            "Epoch 104/150\n",
            "768/768 [==============================] - 0s 161us/step - loss: 0.5441 - acc: 0.7487\n",
            "Epoch 105/150\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.5524 - acc: 0.7331\n",
            "Epoch 106/150\n",
            "768/768 [==============================] - 0s 146us/step - loss: 0.5525 - acc: 0.7357\n",
            "Epoch 107/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.5930 - acc: 0.7292\n",
            "Epoch 108/150\n",
            "768/768 [==============================] - 0s 151us/step - loss: 0.5600 - acc: 0.7214\n",
            "Epoch 109/150\n",
            "768/768 [==============================] - 0s 158us/step - loss: 0.5616 - acc: 0.7292\n",
            "Epoch 110/150\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.5506 - acc: 0.7174\n",
            "Epoch 111/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5391 - acc: 0.7422\n",
            "Epoch 112/150\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.5359 - acc: 0.7448\n",
            "Epoch 113/150\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.5553 - acc: 0.7552\n",
            "Epoch 114/150\n",
            " 10/768 [..............................] - ETA: 0s - loss: 0.8375 - acc: 0.6000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 158us/step - loss: 0.5511 - acc: 0.7409\n",
            "Epoch 115/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5785 - acc: 0.7240\n",
            "Epoch 116/150\n",
            "768/768 [==============================] - 0s 145us/step - loss: 0.5567 - acc: 0.7422\n",
            "Epoch 117/150\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.5751 - acc: 0.7070\n",
            "Epoch 118/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5374 - acc: 0.7487\n",
            "Epoch 119/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5471 - acc: 0.7370\n",
            "Epoch 120/150\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.5723 - acc: 0.7227\n",
            "Epoch 121/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.5757 - acc: 0.7188\n",
            "Epoch 122/150\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.5811 - acc: 0.7201\n",
            "Epoch 123/150\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.5402 - acc: 0.7266\n",
            "Epoch 124/150\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.5433 - acc: 0.7448\n",
            "Epoch 125/150\n",
            "768/768 [==============================] - 0s 149us/step - loss: 0.5591 - acc: 0.7396\n",
            "Epoch 126/150\n",
            "768/768 [==============================] - 0s 145us/step - loss: 0.5413 - acc: 0.7409\n",
            "Epoch 127/150\n",
            "768/768 [==============================] - 0s 153us/step - loss: 0.5507 - acc: 0.7279\n",
            "Epoch 128/150\n",
            "768/768 [==============================] - 0s 149us/step - loss: 0.5543 - acc: 0.7331\n",
            "Epoch 129/150\n",
            "768/768 [==============================] - 0s 149us/step - loss: 0.5521 - acc: 0.7370\n",
            "Epoch 130/150\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.5625 - acc: 0.7279\n",
            "Epoch 131/150\n",
            "768/768 [==============================] - 0s 160us/step - loss: 0.5421 - acc: 0.7370\n",
            "Epoch 132/150\n",
            "768/768 [==============================] - 0s 146us/step - loss: 0.5687 - acc: 0.7331\n",
            "Epoch 133/150\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.5375 - acc: 0.7461\n",
            "Epoch 134/150\n",
            "768/768 [==============================] - 0s 139us/step - loss: 0.5317 - acc: 0.7461\n",
            "Epoch 135/150\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.5566 - acc: 0.7292\n",
            "Epoch 136/150\n",
            "768/768 [==============================] - 0s 140us/step - loss: 0.5398 - acc: 0.7500\n",
            "Epoch 137/150\n",
            " 10/768 [..............................] - ETA: 0s - loss: 0.6453 - acc: 0.7000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 135us/step - loss: 0.5421 - acc: 0.7461\n",
            "Epoch 138/150\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.5588 - acc: 0.7253\n",
            "Epoch 139/150\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.5350 - acc: 0.7422\n",
            "Epoch 140/150\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.5697 - acc: 0.7292\n",
            "Epoch 141/150\n",
            "768/768 [==============================] - 0s 165us/step - loss: 0.5601 - acc: 0.7331\n",
            "Epoch 142/150\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.5252 - acc: 0.7643\n",
            "Epoch 143/150\n",
            "768/768 [==============================] - 0s 155us/step - loss: 0.6135 - acc: 0.7057\n",
            "Epoch 144/150\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.5301 - acc: 0.7539\n",
            "Epoch 145/150\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.5382 - acc: 0.7487\n",
            "Epoch 146/150\n",
            "768/768 [==============================] - 0s 147us/step - loss: 0.5729 - acc: 0.7135\n",
            "Epoch 147/150\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.5540 - acc: 0.7174\n",
            "Epoch 148/150\n",
            "768/768 [==============================] - 0s 152us/step - loss: 0.5301 - acc: 0.7604\n",
            "Epoch 149/150\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.5630 - acc: 0.7344\n",
            "Epoch 150/150\n",
            "768/768 [==============================] - 0s 152us/step - loss: 0.5523 - acc: 0.7279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f538c064fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Ld6dEra3gJoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "18c94a1f-de69-4009-d360-75f0d245fb15"
      },
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(x, y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 64us/step\n",
            "\n",
            "acc: 74.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JJpFEocVkrs-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ref: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/ "
      ]
    }
  ]
}