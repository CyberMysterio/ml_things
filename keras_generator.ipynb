{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gmihaila/toy_models/blob/master/keras_generator.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "g8LvSrDRLJc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use data Generator in Keras\n",
        "\n",
        "by GeorgeM."
      ]
    },
    {
      "metadata": {
        "id": "pEF8oMXXLIkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "c7fd26e7-9302-468c-eee3-1ea05be8c788"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-14 16:52:30--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23278 (23K) [text/plain]\n",
            "Saving to: ‘pima-indians-diabetes.data.csv’\n",
            "\n",
            "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2018-05-14 16:52:30 (3.12 MB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d0iOq0HYLkPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3dff1484-6485-460f-d02b-098da2e5918d"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdatalab\u001b[0m/  pima-indians-diabetes.data.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MfFKQB9oLa4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e4257bfe-a921-420a-e143-cd4eb22c731c"
      },
      "cell_type": "code",
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "data_size = len(X)\n",
        "print 'Data size: ', data_size\n",
        "\n",
        "data = []\n",
        "for x,y in zip(X,Y):\n",
        "  data.append([x,y])\n",
        "print 'Data created'\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def gen(data, mini_batch):\n",
        "    print('Generator initiated!\\n')\n",
        "    # read or split data\n",
        "    data_size = len(data)\n",
        "    x = []    # input batch examples\n",
        "    y = []    # output batch examples\n",
        "    \n",
        "    for index, pair in enumerate(data):\n",
        "      # append data        \n",
        "      x.append(pair[0])\n",
        "      y.append(pair[1])\n",
        "      \n",
        "      if (index+1)%mini_batch == 0:\n",
        "#         print '\\nUsed %s%% of data'%(int(float(index+1)/float(len(data)) * 100))\n",
        "        x = np.array(x)\n",
        "        y = np.array(y)\n",
        "        # output data\n",
        "        yield x, y\n",
        "        x = []; y = []"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size:  768\n",
            "Data created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XMaurYBBZFw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "e86a7724-4d7c-48db-c3ab-6047691a60df"
      },
      "cell_type": "code",
      "source": [
        "# tr_gen = gen(data, 1)\n",
        "# s = time.time()\n",
        "# model.fit_generator(generator=tr_gen, steps_per_epoch=768, epochs=1, max_queue_size=0, workers=0, verbose=2)\n",
        "# e = time.time()\n",
        "# print '\\n\\n Generator: ',(e-s)\n",
        "\n",
        "\n",
        "# steps_per_epoch: batches of examples/examples form Generator to finish 1 epoch\n",
        "# max_queue_size: Integer. Maximum size for the generator queue. Default 10.\n",
        "# workers: Integer. Maximum number of processes to spin up when using process-based threading. Default to 1. \n",
        "         # 0, will execute the generator on the main thread.\n",
        "# epochs: number of times model sees data\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "s = time.time()\n",
        "model.fit(X, Y, epochs=1, batch_size=1)\n",
        "e = time.time()\n",
        "print '\\n\\n Generator: ',(e-s)\n",
        "\n",
        "# evaluate the model\n",
        "\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "del model"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 5.6245 - acc: 0.6510\n",
            "\n",
            "\n",
            " Generator:  2.95914387703\n",
            "768/768 [==============================] - 1s 699us/step\n",
            "\n",
            "acc: 65.10%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}