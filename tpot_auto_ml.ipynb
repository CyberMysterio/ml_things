{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpot_auto_ml.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gmihaila/machine_learning_toolbox/blob/master/tpot_auto_ml.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vQGgkN-3Xm_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [T Pot](https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9)"
      ]
    },
    {
      "metadata": {
        "id": "D9MVOGOzXmZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "191af2dc-b5af-4baf-8767-b452651adc76"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Install pydot\n",
        "print(\"Installing graphiz and pydot\")\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "clear_output()\n",
        "\n",
        "print(\"Installing tpot\")\n",
        "!pip install tpot\n",
        "clear_output()\n",
        "\n",
        "print(\"Downloading pima-indians-diabetes\")\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
        "clear_output()\n",
        "\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pima-indians-diabetes.data.csv\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "asjTy_-fXj8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7cd852c2-a7cc-46e8-d825-e9864f24d9ee"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tpot import TPOTClassifier\n",
        "\n",
        "#scikit-learn package (https://pypi.org/project/scikit-learn)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split #TAKES NUMPY OR DATA FRAME!!\n",
        "from sklearn.metrics.scorer import make_scorer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import itertools\n",
        "\n",
        "#Split train and test set.\n",
        "RANDOM_STATE = 123\n",
        "\n",
        "# Parse data\n",
        "path_file = 'pima-indians-diabetes.data.csv'\n",
        "\n",
        "df = pd.read_csv(path_file, header=None)\n",
        "\n",
        "x_df = df.drop(df.columns[8],axis=1)\n",
        "y_df = df[df.columns[8]]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1   2   3    4     5      6   7  8\n",
              "0  6  148  72  35    0  33.6  0.627  50  1\n",
              "1  1   85  66  29    0  26.6  0.351  31  0\n",
              "2  8  183  64   0    0  23.3  0.672  32  1\n",
              "3  1   89  66  23   94  28.1  0.167  21  0\n",
              "4  0  137  40  35  168  43.1  2.288  33  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "vUzzs5y-Zc_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9d4026d5-5e87-4619-a64a-a07545fb193b"
      },
      "cell_type": "code",
      "source": [
        "X, X_test, y, y_test = train_test_split(x_df, y_df, train_size=0.85, random_state=42)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.85, random_state=RANDOM_STATE)\n",
        "\n",
        "\n",
        "print(\"Train: \", X_train.shape[0])\n",
        "print(\"Validation: \",X_validation.shape[0])\n",
        "print(\"Test: \",X_test.shape[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train: ', 554)\n",
            "('Validation: ', 98)\n",
            "('Test: ', 116)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gUd8bHePZiT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2614
        },
        "outputId": "a2dfc881-f577-4fc9-c3ef-dd4665ddfabd"
      },
      "cell_type": "code",
      "source": [
        "tpot = None\n",
        "del tpot\n",
        "\n",
        "tpot = TPOTClassifier(\n",
        "                      verbosity=3, \n",
        "                      scoring=\"balanced_accuracy\", \n",
        "                      random_state=23, \n",
        "                      periodic_checkpoint_folder=\"tpot_mnst1.txt\", \n",
        "                      n_jobs=-1, \n",
        "                      generations=10, \n",
        "                      population_size=100\n",
        ")\n",
        "\n",
        "tpot.fit(X, y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 operators have been imported by TPOT.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:46<09:57,  1.67pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Created new folder to save periodic pipeline: tpot_mnst1.txt\n",
            "Saving best periodic pipeline to tpot_mnst1.txt/pipeline_2018.10.18_17-07-24.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:48<09:56,  1.68pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:49<09:56,  1.68pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:49<09:56,  1.68pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:51<09:56,  1.68pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:52<09:56,  1.68pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:   9%|▉         | 101/1100 [00:54<09:56,  1.68pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:01<09:03,  1.65pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current Pareto front scores:\n",
            "-1\t0.744062842528\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=18)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Saving best periodic pipeline to tpot_mnst1.txt/pipeline_2018.10.18_17-08-39.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:04<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:04<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:05<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:05<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:07<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:08<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 201/1100 [02:09<18:17,  1.22s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  18%|█▊        | 203/1100 [02:10<42:39,  2.85s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:08<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 2 - Current Pareto front scores:\n",
            "-1\t0.744062842528\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=18)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:10<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:10<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:11<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:17<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:19<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:20<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:21<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:22<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:23<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  27%|██▋       | 301/1100 [03:24<06:36,  2.02pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  28%|██▊       | 303/1100 [03:26<1:15:03,  5.65s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:12<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 3 - Current Pareto front scores:\n",
            "-1\t0.744062842528\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=18)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:12<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:13<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:19<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:21<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:21<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:31<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  36%|███▋      | 401/1100 [05:33<14:29,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  37%|███▋      | 403/1100 [05:39<1:45:37,  9.09s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:00<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 4 - Current Pareto front scores:\n",
            "-1\t0.744062842528\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=18)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:03<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:04<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:07<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:08<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:12<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:13<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  46%|████▌     | 501/1100 [08:19<09:52,  1.01pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 601/1100 [10:14<10:18,  1.24s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 5 - Current Pareto front scores:\n",
            "-1\t0.744062842528\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=18)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 601/1100 [10:15<08:31,  1.02s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 601/1100 [10:20<08:31,  1.02s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 601/1100 [10:24<08:31,  1.02s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 601/1100 [10:28<08:31,  1.02s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 601/1100 [10:29<08:31,  1.02s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  55%|█████▍    | 603/1100 [10:34<29:04,  3.51s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:39<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 6 - Current Pareto front scores:\n",
            "-1\t0.745495270572\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.6000000000000001, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=13, RandomForestClassifier__n_estimators=100)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:44<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:44<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:46<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:47<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:47<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:49<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  64%|██████▎   | 701/1100 [12:51<06:56,  1.04s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [15:57<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 7 - Current Pareto front scores:\n",
            "-1\t0.745495270572\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.6000000000000001, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=13, RandomForestClassifier__n_estimators=100)\n",
            "-2\t0.762472293265\tGaussianNB(GradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=9, GradientBoostingClassifier__max_features=0.8, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=12, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.6500000000000001))\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [15:58<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [16:01<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [16:02<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [16:09<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [16:09<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [16:13<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  73%|███████▎  | 801/1100 [16:17<16:35,  3.33s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:45<03:59,  1.21s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 8 - Current Pareto front scores:\n",
            "-1\t0.745495270572\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.6000000000000001, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=13, RandomForestClassifier__n_estimators=100)\n",
            "-2\t0.765852717899\tRandomForestClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=20, DecisionTreeClassifier__min_samples_split=3), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.7500000000000001, RandomForestClassifier__min_samples_leaf=7, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Saving best periodic pipeline to tpot_mnst1.txt/pipeline_2018.10.18_17-25-23.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:46<03:33,  1.07s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:50<03:33,  1.07s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:55<03:33,  1.07s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:58<03:33,  1.07s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:58<03:33,  1.07s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 901/1100 [18:59<03:33,  1.07s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  82%|████████▏ | 902/1100 [19:03<19:45,  5.99s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 1001/1100 [21:21<02:47,  1.69s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 9 - Current Pareto front scores:\n",
            "-1\t0.745495270572\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.6000000000000001, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=13, RandomForestClassifier__n_estimators=100)\n",
            "-2\t0.765852717899\tRandomForestClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=20, DecisionTreeClassifier__min_samples_split=3), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.7500000000000001, RandomForestClassifier__min_samples_leaf=7, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n",
            "Periodic pipeline was not saved, probably saved before...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 1001/1100 [21:26<04:15,  2.58s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 1001/1100 [21:34<04:15,  2.58s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████ | 1001/1100 [21:37<04:15,  2.58s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  91%|█████████▏| 1005/1100 [21:41<05:15,  3.32s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 10 - Current Pareto front scores:\n",
            "-1\t0.748680631673\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.9000000000000001, RandomForestClassifier__min_samples_leaf=5, RandomForestClassifier__min_samples_split=15, RandomForestClassifier__n_estimators=100)\n",
            "-2\t0.765852717899\tRandomForestClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=20, DecisionTreeClassifier__min_samples_split=3), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.7500000000000001, RandomForestClassifier__min_samples_leaf=7, RandomForestClassifier__min_samples_split=17, RandomForestClassifier__n_estimators=100)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "        disable_update_check=False, early_stop=None, generations=10,\n",
              "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "        mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
              "        periodic_checkpoint_folder='tpot_mnst1.txt', population_size=100,\n",
              "        random_state=23, scoring='balanced_accuracy', subsample=1.0,\n",
              "        use_dask=False, verbosity=3, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "cAnbdjkJZvpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6168d4f-ad7f-4da7-fae4-d5cdba54ff01"
      },
      "cell_type": "code",
      "source": [
        "tpot.score(X_test, y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7822368421052632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "fGxjvnm6fgZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e9ecff9e-5f90-4806-ca46-a3415dbc297c"
      },
      "cell_type": "code",
      "source": [
        "# Winning pipelines\n",
        "print(tpot.fitted_pipeline_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "     steps=[('stackingestimator', StackingEstimator(estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,\n",
            "            max_features=None, max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=20, min_samples_split=...n_jobs=1,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yngce-6nf4nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "324ff66b-f4b8-452f-9899-493d3511b51d"
      },
      "cell_type": "code",
      "source": [
        "tpot.export('tpot_mnist_pipeline.py')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "xTpq_BLIf7NL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "y_predict = tpot.predict(X_test)\n",
        "\n",
        "# Probability of malignant tissue produced by the model\n",
        "y_prob = [probs[1] for probs in tpot.predict_proba(X_test)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-jIoT6QgBl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "494b748a-1bc9-47f3-ebe4-9099a6e7cd14"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy on test set\n",
        "print(\"Test accuracy: %s\"%(accuracy_score(y_test, y_predict).round(2)))\n",
        "\n",
        "# Confusion matrix test set\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(y_test, y_predict),\n",
        "    columns=['Predicted NO', 'Predicted YES'],\n",
        "    index=['Actual NO', 'Actual YES']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted NO</th>\n",
              "      <th>Predicted YES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual NO</th>\n",
              "      <td>60</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual YES</th>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Predicted NO  Predicted YES\n",
              "Actual NO             60             16\n",
              "Actual YES             9             31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "iwfggAmSgDq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "d78ef2ea-eda7-49fa-df4b-83e266ef5fff"
      },
      "cell_type": "code",
      "source": [
        "# Compute area under the curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "#Set default figure size\n",
        "plt.rcParams['figure.figsize'] = (8,8)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"Title\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAHvCAYAAACmMv3vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4U2UDBfCT0Una0kLKKLvslo2s\nggxZsumGMpSlooKKAiKKCFRAQYagiICMQhdllSkoCAIiiIyyVymrg+7dJPf7o5rPKiVdyc04v+fx\nkSTl5vQCPXnveF+JIAgCiIiIyCxIxQ5AREREFYfFTkREZEZY7ERERGaExU5ERGRGWOxERERmhMVO\nRERkRuRiByAiw5szZw5+++03AEBcXBxcXV1hY2MDAKhWrRqmT58ODw8PhIeHw9/fHwDQq1cvLF68\nGO3btxctNxHpxmInskBz587V/rq4wlar1Vi8eLG22InINPBQPBEV0atXL5w9exavvvoqMjIy0L9/\nf8TFxRX5msOHD2Pw4MF46aWXMG7cOCQnJ4uUloj+jcVORM8UHBwMmUyGAwcOoHbt2trn4+LiMH36\ndCxZsgRHjhxBx44d8emnn4oXlIiK4KF4IiqVX375BR06dEDjxo0BAIGBgfDy8oJarYZMJhM5HRGx\n2ImoVDIyMnD27Fn0799f+5xCoUBqaiqqVKkiYjIiAljsRFRKrq6u6NKlC1asWCF2FCJ6Bp5jJ6Jn\nsrKygkajQWZmZpHnu3btirNnz2ovqLt48SLmz58vRkQiegaO2InomZRKJdq1a4eePXtizZo12udd\nXV0xb948vPnmmygoKEClSpUwa9YsEZMS0T9JuB47ERGR+eCheCIiIjPCYiciIjIjLHYiIiIzwmIn\nIiIyIyx2IiIiM2Iyt7upVGqkpGSLHcOsOTvbcx8bAPez/nEf6x/3sWEolQ6l/j0mM2KXyzkHtb5x\nHxsG97P+cR/rH/ex8TKZYiciIiLdWOxERERmhMVORERkRljsREREZoTFTkREZEZY7ERERGaExU5E\nRGRGWOxERERmhMVORERkRljsREREZoTFTkREZEZY7ERERGaExU5ERGRGWOxERERmhMVORERkRvRa\n7Ddu3EDv3r2xZcuW/7x28uRJ+Pr6IiAgAKtWrdJnDCIiIouht2LPzs7GvHnz0Llz52e+Pn/+fKxc\nuRLbtm3Dr7/+ilu3bukrChERkcXQW7FbW1tj7dq1cHV1/c9rcXFxcHJyQo0aNSCVStG9e3ecOnVK\nX1GIiIhMilqtgSAIZfq98grO8v8Ny+WQy5+9+cTERLi4uGgfu7i4IC4uTl9RiIiIKpzjEV/YPDxU\n4dvNzreC/2Y/dK4bh4/2/1Lq36+3YtcHpdJB7Ahmj/vYMLif9Y/7WP8sfh/rodTTcmwweP1IHL9b\nF6dja+GjMmxDlGJ3dXVFUlKS9nF8fPwzD9n/W2Jihj5jWTyl0oH72AC4n/WP+1j/uI8B5V//TxyT\nXiHbS0jIQmBgFC7fTUSNGgqEh48t03ZEud2tVq1ayMzMxIMHD6BSqfDzzz/Dy8tLjChERERG4e7d\nVNy6lYwGDSojOjoQTZpUKdN29DZiv3z5MhYtWoSHDx9CLpfj4MGD6NWrF2rVqoU+ffrg008/xbRp\n0wAAAwYMQP369fUVhYiIyOh17OiGkJDhaNKkClxdK5V5OxKhrJfdicDSD/voGw+tGQb3s/5xH+sf\n9zGg3OQIoHyH4v/88wkSE7PRp0+DZ79HGa5jMKmL54iIiMzFiRP3MXr0LqhUGuzbNwItWui+1qwk\nOKUsERGRge3bdwsjRuxAVlYBBg5shKZNy3Y+/VlY7ERERAYUGhqDceP2IC9PjXHjWmH16pdhZSWr\nsO2z2ImIiAzk22/PYcqUg9BoBLz3Xkd8/nkvSKWSCn0PnmMnIpNRmpm+lLq/hMqJ+7h0Hj3KwMKF\nvwIA5s/vgUmT2urlfVjsRGQy9DF9J1F55Ln1LfHX1qzpgA0bhiAhIRsBAc31lonFTkQmR9ftRbwV\nS/+4j0umoECN8+fj0aFDTQBAz5719P6ePMdORESkB9nZBRg7djeGDw/Hzz/fM9j7csRORERUwdLS\ncjFq1C789ttDVKliBxcXO4O9N4udiIioAsXHFy7mEhOTiJo1FYiI8EWjRi66f2MFYbETERFVkNjY\nNPj5ReLevTS4uzsjIsIHtWo5GjQDi52IiKgCqNUaBAXtwL17aWjRwhWhod5QKu0NnoMXzxEREVUA\nmUyKxYtfQs+edbFjh58opQ5wxE5ERFQuSUnZqFq1sMS7dKmNzp1rQSKp2NnkSoMjdiIiojLas+cG\n2rf/HgcP3tY+J2apAyx2IiKiMtm69TImTtyL7GwVTp16IHYcLR6KJyIiKqVVq85i7txfAAAffNAZ\n77/fSeRE/8diJyIiKiFBEBAc/CuWLz8DAAgO7okJE9qInKooFjsREVEJffbZcaxadRYymQQrVvSD\nn5/+FnMpK55jJyIiKqEBAxrCxcUWP/wwxChLHeCInYiI6Lk0GgFSaeGV7i+8UBNnz06AQmEtcqri\nccRORERUjNTUXAwdGo7du29onzPmUgc4YiciInqm+PhM+PtH4erVJCQkZKF/f3dYW8vEjqUTi52I\niOhf7t1LhZ/fdsTGpqFRIxeEh/uYRKkDLHYiIqIirl5Ngr//dsTHZ6F162rYts0bVaoYbj318uI5\ndiIior+cPfsIQ4eGIT4+C15etbB9u69JlTrAYiciItKyspJBpRLQv787tm3zhoODjdiRSo2H4omI\niP7SqlU17NsXiIYNXSCXm+bY1zRTExERVZDNmy8iIuKK9nHTplVNttQBjtiJiMiCrVhxBvPnn4BM\nJkG7djXQoIGz2JHKjcVOREQWRxAEzJt3HF9/fRYSCbBgQU+zKHWAxU5ERBZGrdbggw8OY8uWy5DL\npfj66/7w9m4qdqwKw2InIiKLkZenwuTJ+7Fnz03Y2sqwfv1g9O7dQOxYFYrFTkREFuPhwwz88st9\nODraYMuWYejUyU3sSBWOxU5ERBajQQNnbN06HLa2crRo4Sp2HL0w3ev5iYiISuDJk0zs2nVd+/iF\nF2qabakDHLETEZEZu3s3FX5+kYiLS4ednRX69jWv8+nPwmInIiKzFBOTiICAKCQkZKFNm2po166G\n2JEMgofiiYjI7Jw58wjDhoUjISEL3brVxvbtfia3mEtZsdiJiMis/PTTXfj5RSItLQ8DBjRESMhw\nKBTWYscyGBY7ERGZjZycArzzziHk5KgwcqQHvv9+EGxtLeuss2V9t0REZNbs7KywefMw7Nt3CzNn\ndoFEIhE7ksGx2ImIyKQJgoALF+LRunV1AIVLr7ZqVU3kVOLhoXgiIjJZgiDg009/Qd++W4ssvWrJ\nOGInIiKTpFJp8P77P2Lr1hjI5VJYWcnEjmQUWOxEInE84gubh4fEjkFkkvLyVHj99X3Yu/cW7Ozk\n2LBhMHr1qi92LKPAYicSCUu9bPLc+oodgUSWmZmPsWN34/jx+3ByKlzMpWNH81vMpaxY7EQiSxyT\nLnYEIpMyefJ+HD9+H0qlPcLDfeDhoRQ7klFhsRMRkUmZObMLHj3KwHffDUSDBs5ixzE6LHYiIjJ6\n6el5cHS0AQA0b67Ejz8GWeQ96iXB292IiMioXbqUgM6dN2DLlkva51jqxWOxExGR0Tp9+iGGD49A\nYmI2oqNvQhAEsSMZPRY7EREZpcOH7yAgYDvS0/MweHAjbNw4hCP1EmCxExGR0dm+/SrGjNmNnBwV\ngoI88d13A2Fjw8vCSoLFTkRERiU0NAaTJ++HSqXBW2+1x9KlfSCTsa5Kih9/iIjIqLRrVwMuLnZ4\n4412mDKlg9hxTA6LnUjPnjV1LKfTICpKEATt+fNGjVzw66+vwMXFTuRUponHNoj07HlTx3J6VKLC\nxVymTDmI778/r32OpV52HLETGcjfU8cqlQ5ITMwQOQ2RccjNVWHSpL04cOA2oqNvYujQJlAq7cWO\nZdJY7EREJIqMjDyMHbsbJ07EoXJlG4SEDGepVwAWOxERGdzTpzkYMSIKf/4Zj2rVKiE83AfNmlUV\nO5ZZYLETEZFBPXyYAX//7bh5Mxl16zohIsIH9epVFjuW2WCxExGRQeXnq5GWlodmzaoiPNwb1aop\nxI5kVljsRERkUPXrV0ZUlC9cXSuhcmVbseOYHd7uRkREenfq1AOsXfuH9nHjxlVY6nrCETsREenV\noUN3MGHCHuTmqtG4cRV0715X7EhmjcVOpfasmdSIiJ4lMvIq3n77ANRqAaNHt0DXrrXFjmT2eCie\nSo2lXnqcYY4s0bp15zF58n6o1QKmTu2AL7/szcVcDIAjdiqzv2dSIyL6J0EQsGTJaSxefAoAMGfO\ni3jzzfYip7IcLHYiIqpQqam52LLlEqRSCZYs6Y2goBZiR7IoLHYiIqpQzs52iIjwxY0bTzFwYCOx\n41gcnuwgIqJyy8kpwK5d17WPGzVyYamLhCN2IiIql4yMPIwevQsnTz5AWloexoxpKXYki8ZiJyKi\nMktKykZgYBQuXkxA9eqV0KFDTbEjWTy9FntwcDAuXLgAiUSCWbNmoWXL/3+KCwkJwe7duyGVSuHp\n6YmPPvpIn1GIiKiCPXiQDn//7bh1KwX161dGRIQP6tRxEjuWxdNbsZ85cwaxsbEICwvD7du3MWvW\nLISFhQEAMjMzsW7dOhw6dAhyuRzjxo3Dn3/+idatW+srDhERVaBr15IwaFAoHj3KhIeHEmFh3nB1\nrSR2LIIei/3UqVPo3bs3AMDd3R1paWnIzMyEQqGAlZUVrKyskJ2dDXt7e+Tk5MDJiZ/yjA1nmCOi\nZxEEAa+8shOPHmWiQ4eaCAkZBicnzvtuLPRW7ElJSfDw8NA+dnFxQWJiIhQKBWxsbPDmm2+id+/e\nsLGxwcCBA1G/fn2d21QqHfQVl/5SZB8/r9TrD+CfRzlw3+kf97F+hYR4Y/7841i1agDs7a3EjkP/\nYLCL5wRB0P46MzMTa9aswYEDB6BQKDB27Fhcu3YNTZs2fe42EhMz9B3ToimVDkX2sfKv/xc7wxz/\nPMrk3/uZKh73sX7cuPEUjRtXAQC4u7tg8eJeyMrKRVZWrsjJzFdZPqDq7T52V1dXJCUlaR8nJCRA\nqSysitu3b6N27dpwcXGBtbU12rdvj8uXL+srChERlVNY2BV0774Jq1adFTsK6aC3Yvfy8sLBgwcB\nADExMXB1dYVCoQAAuLm54fbt28jNLfyUd/nyZdSrV09fUYiIqBy+++4P7QptGRl5YschHfR2KL5t\n27bw8PBAYGAgJBIJ5syZg6ioKDg4OKBPnz4YP348xowZA5lMhjZt2qB9ey4QQERkTARBwKJFJ7F0\n6W8AgM8+647XX28ncirSRSL88+S3keM5M/36zzn2TY4AuIpbReP5X/3jPi4/jUbArFk/Yf36C5BK\nJVi2rC8CA/9/QTT3sWGU5Rw7Z54jIqL/CA4+gfXrL8DaWobvvhuIAQMaih2JSoiLwBAR0X+MHdsK\njRu7YNu24Sx1E8MROxERAShcoc3WVg6JRILatR1x7NgYyGQc/5ka/okRERESErIwcGCo9kI5ACx1\nE8URuwUpyRSxyue+SkTmKC4uHX5+kbhzJxU5OSq89lpbKBTWYseiMuLHMQtSlnnf89z66iEJERmL\n69efYtCgUNy5kwpPTyV27w5gqZs4jtgtUHG3r/H2FSLL8scfjzFy5A4kJ+eiUyc3bNkyDI6ONmLH\nonLiiJ2IyAKdPv0QPj6RSE7ORZ8+9REW5s1SNxMcsRMRWaB69ZxQpYod+vVzx8qV/WBlJRM7ElUQ\nFjsRkQWqXl2BvXtHQKm0h1QqETsOVSAeiicishDffHMOwcEntI+rVavEUjdDHLETEZk5QRCwcOFJ\nfPVV4T3qgwY1QsuW1URORfrCYiciMmNqtQYzZ/6EjRsvQiaTYNmyfix1M8diJyIyU/n5arz11gHs\n3HkdNjYyrF07CP37u4sdi/SMxU5EZIayswswfvweHDlyDwqFNTZvHgovr9pixyIDYLETEZmh7OwC\n3LuXhipV7BAa6o1WrXj43VKw2ImIzFDVqvaIiPBBTo4KjRq5iB2HDIi3uxERmYnY2DSsWHEGgiAA\nAGrVcmSpWyCO2ImIzMDVq0nw99+O+PgsODvbYvTolmJHIpGw2ImITNzZs48wcuQOpKbmoUuXWhg2\nrInYkUhEPBRPRGTCjh2Lha/vdqSm5qFfvwbYtm04HBy4mIslY7ETEZmoPXtuIChoJ7KzC+Dn1wzr\n1w+GnZ2V2LFIZCx2IiITpFJpsGTJaeTnqzFxYhusXNmfK7QRAJ5jJyIySXK5FNu2DceePTcxcWIb\nSCRczIUKccRORGQiBEHAvn23tLez1ajhgEmT2rLUqQiO2M2U4xFf2Dw8JHYMIqogarUG06cfwebN\nl/Deex0xc6aX2JHISLHYzVRxpZ7n1tfASYiovPLz1Zg8eT92774BW1sZ2ratIXYkMmIsdjOXOCZd\n7AhEVA5ZWQV49dXdOHo0Fg4O1tiyZRg6d64ldiwyYix2IiIjlZKSg6CgnTh79jGqVrVDWJgPWrRw\nFTsWGTkWOxGRkZo162ecPfsYtWo5ICLCF+7uzmJHIhPAYiciMlJz53ZHVlYBFi7shZo1HcSOQyaC\nt7sRERmRBw/SodEU3s7m6loJmzYNZalTqbDYiYiMxO+/P0KvXpsxZ84x7b3qRKXFYiciMgI//3wP\nfn6RSE3NQ2xsGlQqjdiRyESx2ImIRLZ79w2MGrUT2dkqBAZ6YP36wZz3ncqMxU5EJKLNmy9i4sRo\nFBRo8NprbbFsWV/I5fzRTGXHq+KJiEQSHn4F06YdBgB8+KEX3nmnA+d9p3JjsRMRiaR37/po1qwq\nXnmlFV59tZXYcchMsNiJiAxIrS68KE4mk8LFxQ4//hgEa2ueT6eKwxM5REQGkpenwsSJezFz5k/a\n29lY6lTRWOxERAaQmZmPoKCdiI6+iaioa7h/nws0kX7wUDwRkZ6lpORg5MgdOHfuCapWtUdYmDfq\n1nUSOxaZKRY7EZEePXmSCX//7bh27Slq13ZERIQPGjTgYi6kPyx2IiI9uX8/Dd7eEbh/Px1NmlRB\neLg3atTgvO+kXyx2IiI9qVzZFo6ONmjbtjq2bh0OFxc7sSORBWCxExHpiaOjDcLCfGBnJ4dCYS12\nHLIQvCqeiKgC/fTTXUyffkS79KpSac9SJ4PiiJ2IqILs2HENb755ACqVBl5etTB0aBOxI5EF4oid\niKgC/PDDBbz++j6oVBpMntwOQ4Y0FjsSWSiO2ImIykEQBCxffgbBwb8CAGbP7oq3336Bi7mQaFjs\nRERlJAgC5sz5Bd9+ew4SCbB4cW+MHdtS7Fhk4VjsRERllJOjwpkzD2FlJcWqVS9j2DCeUyfxsdiJ\niMrI3t4KW7cOx5UriejatY7YcYgA8OI5IqJSyczMx4oVZ7TLr7q42LHUyahwxE5EVELJyTkYMSIK\n58/HIyMjHx991FXsSET/wWInIiqBR48y4O+/HTduJKNOHSeMHOkpdiSiZ2Kxi8TxiC9sHh4SOwYR\nlcCdOynw89uOuLh0NGtWBWFhPqheXSF2LKJnYrGLxBClnufWV+/vQWTuLl1KQEBAFJKSstGuXQ1s\n3ToMzs5czIWMF4tdZIlj0sWOQETPsWjRSSQlZaNHj7rYsGEIKlWyEjsS0XPxqngioudYtao/pk7t\ngM2bh7LUySSw2ImI/uXXX+OgUhXezubkZIuPPuoKGxse4CTTwGInIvqHdev+hLd3BN5770cIgiB2\nHKJS40dQIiIUzvv+1Ve/YeHCkwCAhg2duZALmSQWOxFZPI1GwJw5x7BmzR+QSiX44ouXMHo0F3Mh\n01SiQ/EpKSm4dOkSAECj0eg1EBGRIalUGkydehBr1vwBKysp1q4dyFInk6az2KOjoxEQEIAPP/wQ\nADBv3jxEREToPRgRkSEsX34GYWFXYG9vhZCQ4Rg8uLHYkYjKRWexb9iwAbt27YKzszMAYMaMGQgP\nD9d7MCIiQ3jttbbo1aseIiN90KNHXbHjEJWbznPsDg4OsLP7/yxLtra2sLLivZxEZLqSk3OgUFjD\n2loGhcIaoaHeYkciqjA6i93Z2Rk7duxAXl4eYmJisG/fPri4uBgiGxFRhXv4sHAxF09PJVavfhky\nGe/6JfOi82/03LlzcenSJWRlZWH27NnIy8vDggULDJGNiKhC3bqVjEGDQnHzZjKuXXuK9PQ8sSMR\nVTidI/bjx4/jk08+KfLctm3bMGLECL2FIiKqaBcvxiMwMApJSTlo374Gtm4djsqVbcWORVThii32\nK1euICYmBuvXr0dOTo72eZVKhVWrVrHYichknDwZh1GjdiEzMx89e9bF+vVczIXMV7HFbmNjg6dP\nnyIjIwPnzp3TPi+RSDB9+nSDhCMiKq8zZx4hMDAKublqDBvWBF9/3R/W1jKxYxHpTbHF7u7uDnd3\nd3Tq1AmtW7cu8trBgwf1HoyIqCJ4eirRqlV1NGlSBYsW9eLFcmT2dJ5jd3V1xeLFi5GSkgIAyM/P\nx2+//YZ+/frp3HhwcDAuXLgAiUSCWbNmoWXL/8/m9PjxY7z33nsoKChA8+bN8dlnn5Xj2yAiKkqt\n1kAmk8Le3gphYd6ws5Nz7neyCDo/uk6fPh2VK1fGn3/+CU9PT6SkpGDx4sU6N3zmzBnExsYiLCwM\nCxYs+M+V9AsXLsS4ceMQGRkJmUyGR48elf27ICL6iyAImDv3KMaPj9YuvWpvb8VSJ4uhc8Quk8kw\nadIkHD9+HEFBQfD19cV7772HLl26PPf3nTp1Cr179wZQeFg/LS0NmZmZUCgU0Gg0OHfuHJYuXQoA\nmDNnTgV8K8bJ8YgvbB4eEjsGkUXQaAR8/PFRrF17HlKpBL///gidO9cSOxaRQeks9ry8PDx58gQS\niQRxcXGoWbMmHj58qHPDSUlJ8PDw0D52cXFBYmIiFAoFkpOTUalSJXz++eeIiYlB+/btMW3aNJ3b\nVCoddH6N0XleqdcfYHTfk7HlMVfczxWvoECNceN2Y8uWi7C2lmHbNh8MGdJM7FhmjX+PjZPOYp8w\nYQJOnTqF8ePHY+jQoZDJZBg0aFCp30gQhCK/jo+Px5gxY+Dm5oZJkybh6NGj6NGjx3O3kZiYUer3\nFZvyr/8njkl/9hcY0fekVDqY5D42NdzPFS8npwATJ+7FoUN3YG9vhd27A9GypZL7WY/499gwyvLh\nSWex/304HSg8b56VlQUnJyedG3Z1dUVSUpL2cUJCApTKwppzdnZGzZo1UadOHQBA586dcfPmTZ3F\nTkT0bxkZeRg1aidOnXoIZ2dbbNs2HC+91IClQxar2IvnNBoNQkNDMW/ePERHRwMA5HI5rK2tMXfu\nXJ0b9vLy0t4WFxMTA1dXVygUCu12ateujXv37mlfr1+/fnm/FyKyQFZWMsjlUlSvXgm7dwegbdsa\nYkciElWxI/Z58+YhLS0NrVu3RmhoKFJSUtCwYUN88sknRUbxxWnbti08PDwQGBgIiUSCOXPmICoq\nCg4ODujTpw9mzZqFmTNnQhAENG7cGL169arQb4yILIOtrRwbNw5FSkouatd2FDsOkegkwj9Pfv9D\nYGAgQkNDAQDZ2dno2bMn3Nzc8Nlnn8HT09OgIf9miofWlJsKf9AUe47diPCcmWFwP5ffzZvJWL36\nLBYteumZs8hxH+sf97FhVOg59n+uuW5vb4/69esjJCQEMhmnYiQi8fz55xOMGLEDT5/moHZtR7z3\nXiexIxEZlWKL/d+TOVhbW7PUiUhUJ07cx+jRu5CVVYDevevj9dfbiR2JyOgUW+wJCQmIjIzUPk5M\nTCzy2NfXV7/JiIj+Yf/+W5g0aS/y8tTw9m6KlSv7wcqKgw2ifyu22Nu0aVNkVbfWrVsXecxiJyJD\nCQu7gnfeOQi1WsCrr7bC55/3glTKKWKJnqXYYv/8888NmcPkcepYIv0QBAG7d1+HWi3gvfc6YsaM\nLpz3neg5dE5QQyXzvFLPc+trwCRE5kUikWDt2kE4cOA2vL2bih2HyOix2CuYKdzWRmTsNBoBGzb8\niaCgFrC1lcPe3oqlTlRCOpdtJSIypIICNSZP3ocPP/wZU6ceFDsOkcnRWezXrl2Dt7c3+vfvDwBY\ntWoVLly4oPdgRGR5srMLMHbsbkRFXUelSlYYPbqF2JGITI7OYv/ss88QHBysXcBlwIABvLCOiCpc\nWlouAgKicPjwXbi42CIqyg9du9YROxaRydF5jl0ul6Np0/+f26pfvz7kcp6aJ6KKk5CQhcDAKFy+\nnIgaNRSIiPBB48ZVxI5FZJJKVOxxcXHa20uOHTuGYqaXJyIqkxUrzuDy5UQ0aFAZERG+XMyFqBx0\nFvuMGTMwefJk3L17F+3atYObmxsWL15siGxEZCFmz+72133qnaBU2osdh8ik6Sx2Kysr7NmzB8nJ\nybC2ttauqU5EVB5/j9Dt7a1gayvH559z6WaiiqDz4rk33ngDvr6+iI6ORn5+viEyEZGZO3YsFoMG\nhWLChGgUFKjFjkNkVnSO2A8ePIjLly9j//79CAwMRP369TF06FAMGDDAEPmIyMxER9/E66/vQ36+\nGk5ONmLHITI7JZqgxtPTEx988AFCQkJQs2ZNTJ8+Xd+5iMgMbd16GRMmRCM/X40JE1pj1aqXuUIb\nUQXTOWJPSEjAoUOHcODAASQnJ2PAgAHYu3evIbIRkRlZvfosPv30FwDA++93wgcfdOZiLkR6oLPY\nfXx8MGDAAMyYMQMtWnAWKCIqvV27rmtLfcGCHpg4sa3IiYjMV7HFnpCQAFdXV2zatEk7IU1cXJz2\n9dq1a+s/HRGZhZdfboj+/d0xaFAj+Ps3FzsOkVkrttgXLVqEJUuWYPz48ZBIJEUmpZFIJDhy5IhB\nAhKRacrPVyM/Xw2FwhrW1jJs3DiEh96JDKDYYl+yZAkAYO3atXB3dy/y2vnz5/WbiohMWnZ2AcaN\n24OCAg22bh0GGxs5S53IQIq9Kj49PR3379/HrFmzEBcXp/3vzp07mDlzpiEzEpEJSU3NhZ/fdvz0\n0z1cuZKIuLh0sSMRWZRiR+zgKxtJAAAgAElEQVTnz5/Hxo0bcfXqVYwdO1b7vFQqRdeuXQ0SjohM\nS3x8FgICtuPKlSS4uTkgIsIHDRu6iB2LyKIUW+zdu3dH9+7dsW3bNowYMcKQmYjIBMXGpsHPLxL3\n7qWhUSMXhIf7wM3NQexYRBan2GLfvn07fHx8EB8fj+XLl//n9alTp+o1GBGZjri4dAwaFIr4+Cy0\nalUN27YNR9WqXMyFSAzFFrtUWnj6nWuvE5EuNWoo0KZNdWRk5GHTpqFwcOBUsURikQglWFw9MzMT\nCoUCSUlJuHfvHtq2bastfkNKTMww+HuWlHJT4frRiWNM90IhpdLBqPexuTCn/SwIgvZq99xcFQDA\n1lb8wYA57WNjxX1sGEpl6U9n6WznefPmYf/+/UhNTUVgYCC2bNmCTz/9tCz5iMiM7NlzA76+25Gd\nXQCgsNCNodSJLJ3OYr9y5Qr8/Pywf/9+DB8+HMuWLUNsbKwhshGRkdqy5RImTtyL48fvIyrqmthx\niOgfdBb730fqjx49il69egEA12UnsmArV/6O9977ERqNgBkzuiAoyFPsSET0DzqPm9WvXx8DBgyA\ni4sLmjVrhp07d8LJyckQ2YjIiAiCgPnzT2Dlyt8BAJ9/3gvjx7cWORUR/ZvOYp8/fz5u3LihnVa2\nYcOGWLx4sd6DEZHxUKs1mD79CDZvvgS5XIqVK/vBx6eZ2LGI6Bl0Fntubi5++uknLF++HBKJBK1b\nt0bDhg0NkY2IjEhGRj5sbWVYt24w+vRpIHYcIiqGznPsH3/8MTIzMxEYGAh/f38kJSVh9uzZhshG\nREZCJpPi66/7Y+/eESx1IiOnc8SelJSEpUuXah/37NkTo0eP1msoIhJfSkoOgoN/xZw5L2qXXm3R\nwlXsWESkg85iz8nJQU5ODuzs7AAA2dnZyMvL03swIhLPkyeZCAjYjqtXnyI3V4WVK/uLHYmISkhn\nsQcEBODll1+Gp2fhLS0xMTGcJ57IjN29mwo/v+24f79wMZcPP/QSOxIRlYLOYvf19YWXlxdiYmIg\nkUjw8ccfo1q1aobIRkQGduVKIvz9o5CQkIXWrath2zZvVKliJ3YsIiqF5xb7sWPHcOfOHbRr1w69\ne/c2VCYiEsGZM48QFLQDaWl56NatNjZuHAqFwlrsWERUSsVeFb9y5Up88803SEhIwOzZs7F7925D\n5iIiA4uMvIq0tDy8/LI7QkKGs9SJTFSxI/YTJ04gJCQEcrkcGRkZePvttzFkyBBDZiMiAwoO7omm\nTatgzJiWkMsNv3ojEVWMYv/1Wltba9did3BwgFqtNlgoIjKMXbuuIz298C4XuVyKceNas9SJTFyx\n/4L/XmO5uMdEZLoEQcCKFWcwceJejBq1EyqVRuxIRFRBij0Uf/v2bUyfPr3Yx5wvnsg0CYKAuXN/\nwerV5yCRAN7eTTlKJzIjxRb7+++/X+Rx586d9R6GiPRLrdbg/fcPIyTkMuRyKVat6o/hw5uKHYuI\nKlCxxT58+HBD5iAiPcvLU+GNN/YjOvom7OzkWL9+MF56qb7YsYiogumcoIaIzMPmzZcQHX0Tjo42\nCAkZho4d3cSORER6wGInshCvvtoKt24lY9SolvD0VIodh4j0pETFnpKSggcPHqBFixbQaDSQSnmh\nDZEpePIkE9bWMri42EEmk2LhwpfEjkREeqazoaOjoxEQEIAPP/wQADBv3jxEREToPRgRlc+dOykY\nNCgUQUE7kJmZL3YcIjIQncW+YcMG7Nq1C87OzgCAGTNmIDw8XO/BiKjsLl9OxODBYbh/Px2CABQU\ncIIpIkuhs9gdHBy0a7EDgK2tLaysrPQaiojK7rffHmLYsHAkJmajW7c6iIz0hbMzV2gjshQ6z7E7\nOztjx44dyMvLQ0xMDPbt2wcXFxdDZCOiUjpy5C7GjduDnBwVBg5siG+/HQAbG14jS2RJdI7Y586d\ni0uXLiErKwuzZ89GXl4e5s+fb4hsRFQKFy7EY/ToXcjJUSEoyBNr1w5iqRNZIJ3/6h0dHfHJJ58Y\nIotoHI/4wubhIbFjEJVLixau8PFpiqpV7fHJJ924vgORhdJZ7N27d3/mD4ijR4/qI48oKqrU89z6\nVsh2iEpKEARkZRVAobCGVCrB8uX9IJWy0Iksmc5i37p1q/bXBQUFOHXqFPLy8vQaSiyJY9LFjkBU\nYoIgYM6cX3DixH3s3OkPR0cbljoR6T7H7ubmpv2vXr16GDFiBI4fP26IbERUDJVKg3feOYRvvz2H\n69ef4o8/nogdiYiMhM4R+6lTp4o8fvLkCe7fv6+3QET0fLm5Krz22l7s338b9vZyrF8/BD161BU7\nFhEZCZ3Fvnr1au2vJRIJFAoF5s6dq9dQRPRsmZn5GDt2F44fj4OTkw1CQoajQ4eaYsciIiOis9hn\nzpwJDw8PQ2QhoufIzMyHj08Ezp+Ph6trJYSFecPDg4u5EFFROs+xL1q0yBA5iEiHSpWs0KJFNdSt\n64To6ACWOhE9k84Re82aNTF69Gi0atWqyFSyU6dO1WswIipKIpFg0aJeSE3NQ5UqnCKWiJ5N54i9\nVq1a6NixI2xtbSGTybT/EZH+XbqUAG/vCCQn5wAAZDIpS52InqvYEfvu3bsxZMgQvPXWW4bMQ0R/\nOX36AYKCdiIjIx/Ll5/B3LndxY5ERCag2BF7ZGSkIXMQ0T/8+OMd+PtvR0ZGPoYMaYxZs7zEjkRE\nJkLnoXgiMqzIyKsYO3Y3cnPVGD26Bdas4QptRFRyxf60OH/+PHr06PGf5wVBgEQiMau54omMxbp1\n5/Hhhz8DAKZMeQEffdSVi7kQUakUW+zNmzfH0qVLDZmFyOLdu5cGAPj44254++0XRE5DRKao2GK3\ntraGm5ubIbMQWby5c7ujf393eHnVFjsKEZmoYs+xt2zZ0pA5iCySSqXBggUnkJiYDQCQSiUsdSIq\nl2KL/YMPPjBkDiKLk5urwrhxe7B8+RmMH78HgiCIHYmIzIBer4oPDg5GQEAAAgMDcfHixWd+zZIl\nSzB69Gh9xiAyOhkZeRgxIgoHDtxG5co2mDPnRV4kR0QVQm/30Jw5cwaxsbEICwvD7du3MWvWLISF\nhRX5mlu3buH3338vMlUtkblLTMyCt3ckLlyIR/XqlRAe7oOmTauKHYuIzITeRuynTp1C7969AQDu\n7u5IS0tDZmZmka9ZuHAh3n33XX1FIDI6Dx6ko1u3DbhwIR716jlhz55AljoRVSi9FXtSUhKcnZ21\nj11cXJCYmKh9HBUVhQ4dOvDKe7IoUVHXcP36UzRvXhV79gSibl0nsSMRkZkx2HRW/7wwKDU1FVFR\nUdiwYQPi4+NLvA2l0kEf0Qy2fVPAfaBfn33WC87O9nj11dZwduZiLvrEv8v6x31snPRW7K6urkhK\nStI+TkhIgFJZuH706dOnkZycjKCgIOTn5+P+/fsIDg7GrFmznrvNxMQMvWT9e1VrfW3fVCiVDha/\nD/Th9OmHqFfPCdWrKwAA773XGYmJGdzXesS/y/rHfWwYZfnwpLdD8V5eXjh48CAAICYmBq6urlAo\nCn+w9e/fH/v27UN4eDi+/vpreHh46Cx1IlN04MBt+PlFwt9/O9LT88SOQ0QWQG8j9rZt28LDwwOB\ngYGQSCSYM2cOoqKi4ODggD59+ujrbYmMRnj4FUydehBqtYCOHd1QqRLv/iAi/ZMIJjQrht4OxW9y\nLNz+mHS9bN9U8NBaxfnuuz8we/ZRAMC773bEzJldtPepcz/rH/ex/nEfG0ZZDsVzLUiiCiQIAr74\n4hS+/PI0gMK53994o53IqYjIkrDYiSrQzz/fw5dfnoZUKsFXX/XBiBGeYkciIgvDYieqQD171sOb\nb7ZH+/Y1MHBgI7HjEJEFYrETlVNOTgHS0vJQvbrirwtFXxQ7EhFZML0uAkNk7tLT8xAQEIXhwyO0\nS68SEYmJxU5URgkJWRg2LBynTz9EdnYBUlNzxY5ERMRD8URlEReXDj+/SNy5k4r69SsjIsIHdepw\n3nciEh+LnaiUbtx4Cn//7Xj0KBOenkqEhnrD1bWS2LGIiACw2IlKJSEhC0OGhCE5ORcdO7phy5ah\ncHKyFTsWEZEWi52oFFxdK2HUqBa4ciUJ338/CPb2nCaWiIwLi52oBPLyVLCxKfzn8tFHXaFWC5DL\nee0pERkf/mQi0iE0NAbdu2/CkyeZAACJRMJSJyKjxZ9ORM/x7bfnMGXKQdy5k4p9+26JHYeISCce\niid6BkEQsHDhSXz11W8AgHnzemDcuNYipyIi0o3FTvQvGo2AmTN/wg8/XIBMJsGyZf0QENBc7FhE\nRCViUcXueMQXNg8PiR2DjJhGI2Dy5H2IiroOGxsZ1q4dhP793cWORURUYhZV7M8r9Ty3vgZMQsZK\nKpWgYUMXKBTW2Lx5KLy8aosdiYioVCyq2P+WOCZd7AhkxKZN64TAQA/UquUodhQiolLjVfFk8RIS\nsjBq1E48eFD4gU8ikbDUichkWeSInehv9++nwc9vO+7eTYVEAmzePEzsSERE5cJiJ4t1/fpT+PlF\n4smTLLRo4YqlS3mdBRGZPh6KJ4v0xx+PMWRIGJ48yULnzm7YscMPSqW92LGIiMqNxU4W59ixWHh7\nRyIlJRd9+zZAaKg3HB1txI5FRFQhWOxkcWJiEpGdXQBf32bYsGEw7Oy4QhsRmQ+eYyeLM3lye7i7\nO6NPnwaQSiVixyEiqlAcsZNFWL/+T9y9m6p93K+fO0udiMwSi53MmiAICA4+gZkzf0JAwHbk5qrE\njkREpFc8FE9mS63WYMaMn7Bp00XIZBJ88EFn2NryrzwRmTf+lCOzlJ+vxltvHcDOnddha1u4mEu/\nflzMhYjMH4udzE5WVgHGjduNn3+OhYODNbZsGYbOnWuJHYuIyCBY7GR2Dh++g59/jkXVqnYIDfVG\ny5bVxI5ERGQwLHYyO0OHNkF8fBZ69aqHhg1dxI5DRGRQLHYyC7GxaSgoUGuLfNKktiInIiISB293\nI5N39WoSBg0KhZ/fdjx8mCF2HCIiUbHYyaSdPfsIQ4eGIT4+C/XqOcHR0VrsSEREomKxk8k6ejQW\nvr6RSE3NQ//+7ti2zRsODlzMhYgsG4udTNKePTcQFLQD2dkqBAQ0x/r1gzn5DBERWOxkgm7fTsHE\niXtRUKDBa6+1xfLl/SCX868yERHAq+LJBLm7O2P27K7Iz1fj3Xc7QiLhYi5ERH9jsZNJEAQB8fFZ\nqF5dAQB4660XRE5ERGScePySjJ5arcG0aT+id+8Q3LuXqvs3EBFZMBY7GbW8PBUmTdqLLVsuIz09\nF/fupYkdiYjIqPFQPBmtzMx8vPrqHhw7VriYS0jIMHTqxMVciIieh8VORiklJQcjR+7EuXOPUbWq\nPcLCvNGihavYsYiIjB6LnYxOXp4Kw4ZF4OrVJNSu7YiICB80aOAsdiwiIpPAc+xkdGxs5Bg9ugUa\nN3bBnj0BLHUiolLgiJ2Mhkql0U40M2FCGwQFecLOzkrkVEREpoUjdjIKZ848QteuP+DmzWTtcyx1\nIqLSY7GT6H766S78/CJx504qvv/+vNhxiIhMGoudRLVz53WMHr0LOTkqjBjhgQULeoodiYjIpLHY\nSTQbN17Ea68VLubyxhvtsGxZXy7mQkRUTrx4jkSxYsUZzJ9/AgDw0UddMWXKC1zMhYioArDYSRTO\nzraQSiVYuLAXXnmlldhxiIjMBoudRDF6dEt06lQLjRq5iB2FiMis8IQmGURengrvvHMQV64kap9j\nqRMRVTwWO+ldZmY+Ro7cia1bYzBp0l6o1RqxIxERmS0eiie9Sk7OwciRO/DHH0+gVNrj228HQibj\n50kiIn1hsZPePH6cAX//KFy//hR16jgiPJyLuRAR6RuLnfTizp0U+PltR1xcOpo2rYKwMG/UqOEg\ndiwiIrPHYie9uHgxAXFx6WjXrjq2bh0OZ2c7sSMREVkEFjvpxbBhTWBtLcOLL9aBQmEtdhwiIovB\nq5iowhw5chcXLsRrHw8Y0JClTkRkYCx2qhBRUdcwevQuBAZG4fHjDLHjEBFZLBY7lduGDRfwxhv7\noFJpEBjogerVFWJHIiKyWDzHTmUmCAKWLTuDzz//FQAwe3ZXTJnSQeRURESWjcVOZaLRCJgz5xjW\nrPkDEgnwxRe9MWZMS7FjERFZPBY7lcmffz7Bd9/9ASsrKVavfhlDhzYROxIREYHFTmXUtm0NfPVV\nX1SvrkCvXvXEjkNERH9hsVOJZWbm4969NHh6KgEAI0d6ipyIiIj+jVfFU4k8fZoDb+8IeHuHF1l6\nlYiIjAuLnXR6+DADQ4aE4c8/4+HkZAt7eyuxIxERUTF4KJ6e6/btFPj5ReLBgww0a1YF4eE+qFaN\n96kTERkrFjsV6+LFeAQGRiEpKQft29fA1q3DUbmyrdixiIjoOVjs9Ezp6Xnw89uOlJRc9OhRFxs2\nDEGlSjwET0Rk7PRa7MHBwbhw4QIkEglmzZqFli3/P4HJ6dOnsXTpUkilUtSvXx8LFiyAVMpT/sbC\n0dEG8+b1wOHDd7FyZT/Y2PAzIBGRKdBbk545cwaxsbEICwvDggULsGDBgiKvf/LJJ1ixYgVCQ0OR\nlZWF48eP6ysKlcLTpznaX/v7N8eaNQNY6kREJkRvxX7q1Cn07t0bAODu7o60tDRkZmZqX4+KikL1\n6tUBAC4uLkhJSdFXFCqhlSt/Q8eO63Hx4v+XXpVIJCImIiKi0tLbUCwpKQkeHh7axy4uLkhMTIRC\nUXhF9d//T0hIwK+//oqpU6dW2Hs7HvGFzcNDFbY9cycIAr788jS++OIUAOD33x+jZctqIqciIqKy\nMNgxVkEQ/vPc06dP8frrr2POnDlwdnbWuQ2l0qFkb/a8Uq8/oOTbsQAajYB33z2AFSvOQCqV4Lvv\nBmH8+LZixzJ7/Duof9zH+sd9bJz0Vuyurq5ISkrSPk5ISIBSqdQ+zszMxMSJE/HOO++ga9euJdpm\nYmJGib7u73dJHJNezIZKth1zV1CgxjvvHEJExFVYW8uwbZsPunWrVeL9TGWjVDpwH+sZ97H+cR8b\nRlk+POntHLuXlxcOHjwIAIiJiYGrq6v28DsALFy4EGPHjsWLL76orwj0HIIg4PXX9yEi4irs7a0Q\nEjIM3t7NxI5FRETlpLcRe9u2beHh4YHAwEBIJBLMmTMHUVFRcHBwQNeuXbFz507ExsYiMjISADBo\n0CAEBAToKw79i0QiwdChTXDq1ANs3jwM7drVEDsSERFVAInwrJPfRqrEh+I3ORZ+fXGH4i2YIAhF\nrnTPyMiDg4MNAB5aMxTuZ/3jPtY/7mPDMKpD8WR8HjxIR58+Ifj990fa5/4udSIiMg8sdgtx61Yy\nBg8Ow8WLCQgOPvHMuxSIiMj0cUoxC3DxYjwCAqLw9GkOOnSoiR9+GMKJZ4iIzBRH7Gbu5Mk4DBsW\ngadPc/DSS/UQHu4DJyeu0EZEZK5Y7Gbs4MHbCAiIQmZmPoYPb4KNG4fC3p4rtBERmTMWuxkTBECl\n0uCVV1ph9eqXYW0tEzsSERHpGc+xm7H+/d1x6FAQPD2VPKdORGQhOGI3I4IgYMmS0zh16oH2uRYt\nXFnqREQWhCN2M6HRCPjoo5+xbt2fqFzZBmfPToCjI+9RJyKyNCx2M1BQoMaUKQexffs1WFvLsGxZ\nP5Y6EZGFYrGbuJycAkyYEI0ff7yLSpWssGnTUHTrVkfsWEREJBIWuwlLT8/DqFE7cfr0Q7i42GLb\nNm+0aVNd7FhERCQiFrsJi4lJxLlzj1GjhgLh4T5o0qSK2JGIiEhkLHYT1rlzLaxfPxjNmlVFnTpO\nYschIiIjwGI3MdevP0VCQpb2PHq/fu4iJyIiImPC+9hNyPnzTzB0aBhGj96FS5cSxI5DRERGiMVu\nIo4fvw9v7wgkJ+fCy6sW3N2dxY5ERERGiMVuAvbtu4URI3YgK6sA3t5N8cMPQ7iYCxERPROL3cht\n23YZ48btQX6+GuPHt8bq1S/DyoqLuRAR0bPx4jkj9uRJJmbMOAKNRsC0aZ0wfXpnzvtORETPxWI3\nYtWrK7BmzUDExaVj0qS2YschIiITwGI3MhqNgCtXkuDpqQQAvPxyQ5ETERGRKeE5diOSn6/GG2/s\nw4ABW4ssvUpERFRSHLEbiezsAowfvwdHjtyDQmENjUYQOxIREZkgFrsRSEvLRVDQTpw58whVqtgh\nNNQbrVpVEzsWERGZIBa7yOLjsxAYGIWYmES4uTkgPNwHjRq5iB2LiIhMFItdRBqNoC11d3dnRET4\noFYtR7FjERGRCePFcyKSSiX4+ONuaNeuBnbvDmCpExFRuXHELoLMzHwoFNYAgF696qFHj7qQSjnx\nDBERlR9H7AZ27Fgs2rX7HkePxmqfY6kTEVFFYbEb0J49NxAUtBMpKbmIjr4pdhwiIjJDLHYDCQm5\nhIkT9yI/X40JE1pj8eKXxI5ERERmiOfYDWDVqrOYO/cXAMAHH3TG++934mIuRESkFyx2PVuy5DQW\nLToJAAgO7okJE9qInIiIiMwZi13POnVyQ6VKVli8+CX4+TUXOw4REZk50yn2JRIoxc5QQoIgaA+1\ne3nVxtmzE1Clip3IqYiIyBKY7cVzeW59RXnfrKwCjBq1Ez/+eEf7HEudiIgMxXRG7AASx6SLHeG5\nUlJyEBS0E2fPPsa1a0/x4ot1YGNjUruYiIhMHFungsTHZ8LffzuuXn2KWrUKF3NhqRMRkaGxeSrA\nvXup8PPbjtjYNDRq5ILwcB+4uTmIHYuIiCwQi72crlxJREBAFOLjs9C6dTVs2+bNc+pERCQas714\nzlAyMwuQnp6Hrl1rIyrKj6VORESi4oi9nDp0qImdO/3RrFlV2NpydxIRkbjYRGWwZ88NAMDgwY0B\nAG3aVBczDhERkRaLvZQ2b76IDz44ArlcimbNqqJhQxexIxEREWnxHHsprFhxBtOmHYZGI2DatE5w\nd3cWOxIREVERHLGXgCAImDfvOL7++iwkEmDhwpfw6qutxI5FRET0Hyx2HdRqDT744DC2bLkMuVyK\nr7/uD2/vpmLHIiIieiYWuw5376Zix47rsLOTY926Qejdu4HYkYiIiIrFYtehYUMXbN48FHK5DJ06\nuYkdh4iI6LlY7M+QkpKDc+cea0fnXbvWETkRERFRyfCq+H958iQTw4aFY/ToXfjpp3tixyEiIioV\njtj/4c6dFPj7R+H+/TQ0aVIFzZpVETsSERFRqbDY/xITkwh//+1ITMxG27bVsXXrcLi4cN53IiIy\nLTwUD+C33x5i6NBwJCZmo1u3OoiM9GWpExGRSbL4Ys/NVWHixGikp+dh4MCG2Lp1GBQKa7FjERER\nlYnFH4q3tZVj7dpBiIq6hgULekIut/jPOkREZMIstthv3UrWLuDSsaMbOnbkPepERGT6LG54KggC\nli37Dd26bUR09E2x4xAREVUoixqxC4KATz/9Bd98cw4SCZCcnCN2JCKicnv8+BHGjAlEkyaF61gU\nFBSgQYOGeP/9mZDJZMjNzcXKlUtx5cplyOVyODtXwbRpM1CtWnUAQFzcfaxYsQSpqSlQqzVo0aIl\n3nzzHVhbi3e9kVqtxowZ7+Ldd6fDza2WaDkyMzMxd+5HyMzMhJ2dPT79dD4cHZ2K5Pzii2DExd1H\nQUEBvL390L//QFy+fBGrVi2HXC6HlZU1Pv74M1y5chlnz57B1KnT9JrZYkbsKpUG7757CN98cw5y\nuRRr1gzEmDEtxY5FRFQh6tSpi6+//g5ff/0d1qzZAJWqAD/+eAAAsHLlUlStqsSGDVuxdu0mjBo1\nFtOmTYFKpYJarcbs2dMxcuQYrF27CevWbQYAbNiwVsxvBzt3RqJVqzailjoAhIdvRZs27fDNN+vQ\nvXtPbNmyscjrp0+fRE5ODlatWouVK7/FN9+shEajQWhoCGbPnouVK9fA07MF9uzZAS+vbnjy5BGu\nXo3Ra2aLGLHn5qrw+uv7sG/fLdjZybFhw2D06lVf7FhERHrTvLknHjyIQ3Z2Fk6fPomwsJ3a11q2\nbI3mzT1w/PhR2NnZo06demjTph0AQCKRYPLkKZBIio77VCoV5s+fg/j4x7C2tsFXXy3BgQNHcOfO\nbbz11jvIzs7GmDEBiIzcg8DA4ejUyQvOzs7Yv38vQkOjAAD790fj1q0bGDFiND7/fB5UqgJIpVLM\nmPExqlevXuT9IiPDsGbNBgDAoUP7ERkZBplMinr13DFjxkfYt28PTp8+iaSkRMydG4xffjmKw4cP\nQCKRolu3HhgxYhQSEuIxb94n2vyzZ88t8kHh5MkT2Lp1U5H3HTLEG3379tc+Pnfud3z4YeE2vLxe\nxPTp7xT5eienysjMzIRGo0F2dg7s7e0hlUoxf/4iAIVHihMTE9GyZeFS397e/oiICMUnn8wrzR9n\nqVhEsU+ZchD79t2Ck5MNtmwZxgvliEhvHI/4wubhoQrdZp5bX6S/FFnir1epVDh+/BiGDfPBw4cP\nULduPcjlRX/cN2rUBPfvx8LOzg6NGjUu8pqNje1/trl/fzSqVKmCTz9dgMOHD+LIkSPPff9Onbqg\nU6cu+OOPs7hz5zYaNHDH8ePHMGLEKKxd+w0CA4PwwgsdcerUCWzc+D1mzJit/f1PnjyBtbW19pB3\nTk4OlixZCQcHB7z55kTcvn0LABAf/wTffrsejx8/wtGjR7B69ToAwBtvjEfPnr2RkvIUr746EW3b\ntkd09C5ERUXg7bff1b5Ply5d0aVL1+fuy6dPn6JyZWcAgLOzM54+TSryuqdnC1SrVg1+fkOQlZWl\n/RAAFI7mly37EvXq1UO/fgMAAC1btsLnn3/23PcsL4so9smT2+HixXisWzcYHh5KseMQEVW4+/dj\n8dZbkwAAt2/fQlDQGLz4Yg/cvHkDarXmP18vCAKkUhkACTSa/77+b9evX0P79i8AAHr37gel0gEb\nN24t9uubN/cAALz4YmaEZV0AABEoSURBVE/8+utxuLnVwt27t+Hp2RILF87D/fux2LhxHTQajbY4\n/5aUlAil0lX72NHRER9+WHheOjb2LtLSUgEAzZo1h0QiwdWrMXjwIA5vv/0aACA7OwtPnjxCjRo1\nsWzZl1i3bg0yMtLRpEkznd/n8wiC8J/nLlw4j4SEeISF7URKSjKmTHkdXbp0hZWVFTp16oJt27bj\nm29WYsuWHzBmzDjY2NhqT4HIZLJy5SmO2RZ7bq4KtraF317r1tVx4sQrvEediPSuNCPrivT3OXYA\nmD17OmrXrgsAcHNzQ1xcLAoKCmBlZaX9+lu3buDFF3vAysoa27eHF9lWfn4+Hjy4jwYNGmqfk8mk\n0GiKFptEItH+WqVSFXlNLi98r+7de+Ljj2eiQQN3dOzYGRKJBHK5FebNW4SqVasW+/38ve2CggIs\nXboYP/ywFVWqVC1yKPzv95DLrdC5sxemT/+oyDaCg+eiY8dOGDbMFz//fBgnT54o8npJDsVXrVoV\nyclJUCgUSEpKRNWqRQeHly5dQLt2HSCXy6FUusLR0QkJCfG4desmunfvCYlEgh49emH9+u+K/V4r\nmlk23Z07/2vv3qNjuvc+jr/HRCgihFxIonosjtupukSFiIZE41bLWVmJkEuTNGkiWtSqJULj0rgm\nrUo5PO1CXUpU0+eUQyhHquRSGoREG6JuQeRSmpDbyH7+8MgxJwxJOyYzvq+1/GF+s/f+5rPEd/9m\n7/nt33Bx+YKvvz5b+5o0dSHE82LKlGmsXZtARUUFLVq0ZPDgoVqN5fTpU+Tm/oKzswtOTq9SUHCd\nI0cOA1BTU8M//pHAwYPfae2ze/eeZGYeA+Do0R9Yu3YtLVq0rP1oOivr5CNrad/eGpVKxYED+3jt\ntRHA/ev/P/yQAty/hr1/f3KdbW7evAncn32r1WratWtPQcENfv75bJ2TiL/+tQeZmT9RUVHx/19p\njqOysoJbt25hb++AoigcOfI91dXVWtsNHuxSe8Phgz8PN3WAgQMH8e9/HwAgJeUgr77qrDXu4OBY\nezPcnTtlFBbepH379qxf/z+cO/cLADk5Z+jU6f6JVmVlBWZmZnqbrYMJNvbTp28ydmwily/f5osv\nsuqcYQohhKnr2NGe114bwRdf3L/mPG3aTKqqKgkM9CU0NIBNm9azaNFS1Go1TZo0IT7+U7799htC\nQvyZMuUtWrVqRUjI21r7dHd/nfLycqZODWPHjm1MmDCBAQOcai8BXL58sc4Ndw+4uLhy8mQmL7/8\nCgAhIWH88EMKkZGhbNjwGb17/03r/XZ2dlRWVvL7779jadkGJ6dXeeutADZs+IxJk/xZteojreZu\nZ2eHt7cvkZGhhIW9Sbt27WjWrDnjx/+djz9ewcyZ7zJixOucPJnJjz+m1ytLL6+J/PLLWaZMeYvM\nzJ+YNCkAgE8+iefatXxcXd1o1aoVEREhvPfeO0yZ8i7NmjUnKmoe8fHLiIwMJTX1CP7+QQCcPp1F\nnz5961VDfamUR100aIySxlA4dLvOt6SnX2Xy5P+ltLSKYcNeZMOGcbLuez1YW1tQWFhq6DJMnuSs\nf5Kx/uk746++2k5lZQV+fm/q7RiGMGfO+/j5BdKzZ++ner+1tUW9j2E8M/a//0vn8HffXcDb+2tK\nS6sYN64rW7aMl6YuhBBGasIEL06ezCQ//6qhS/nTpKYewcbG9qmbekMZz4wdHnt2uGtXLm+/vQeN\npgY/v96sWOGOWm085yyNhcxyng3JWf8kY/2TjJ+NhszYTeKu+L/8pS0tWjQlIOBvzJs3VOtOTSGE\nEOJ5YhKNvVcvaw4fDqBjx/qf2QghhBCmxCg/r66pUZg3L4UvvzxT+5o0dSGEEMIIZ+wPHuaSmJjD\nCy+YMWLES9jatjR0WUIIIUSjoNfGvnjxYk6dOoVKpWLOnDm8/PJ/nqaWmprKRx99hFqtxtXVlcjI\nyCfur6JCQ1jYv0hOzqNFCzM2bHhDmroQQgjxEL19FP/jjz9y6dIlEhMTiY2NJTY2Vmv8ww8/JCEh\ngW3btnH06FHOnz+vc3+//17JpEnfkJycR5s2zfjqKy/c3Drrq3whhBDCKOmtsaelpeHu7g5Aly5d\nuH37NmVlZQBcuXIFS0tLOnToQJMmTRg2bBhpaWk69zdixCaOHLmCrW1L/vlPH5ycOuqrdCGEEMJo\n6a2xFxUV0bbtf57YY2VlRWFhIQCFhYVYWVk9cuxxfv31N1580ZJdu3zo0ePxDw4QQgghnmfP7Oa5\nP7oOTlHRrD+pEqFLQxZDEPUnOeufZKx/knHjpLcZu42NDUVF/3kg/c2bN7G2tn7kWEFBATY2NnX2\nIYQQQoj60VtjHzJkCPv27QMgOzsbGxsbWrVqBYCDgwNlZWVcvXoVjUbDoUOHGDJkiL5KEUIIIZ4b\nel0rPi4ujuPHj6NSqYiJiSEnJwcLCws8PDw4duwYcXFxAIwcOZKQkBB9lSGEEEI8N4zqITBCCCGE\n0M0ol5QVQgghxKNJYxdCCCFMSKNs7IsXL8bHx4eJEyeSlZWlNZaamoqXlxc+Pj6sXr3aQBUaP10Z\np6en4+3tzcSJE4mKiqKmpsZAVRo3XRk/EB8fj7+//zOuzHToyvj69ev4+vri5eXFBx98YKAKTYOu\nnLdu3YqPjw++vr51VhgVTy83Nxd3d3e2bNlSZ6zefU9pZDIyMpSwsDBFURTl/Pnzire3t9b4qFGj\nlGvXrin37t1TfH19lXPnzhmiTKP2pIw9PDyU69evK4qiKO+8846SkpLyzGs0dk/KWFEU5dy5c4qP\nj4/i5+f3rMszCU/K+N1331X279+vKIqizJ8/X8nPz3/mNZoCXTmXlpYqbm5uSnV1taIoihIUFKSc\nOHHCIHUaszt37ih+fn7K3Llzlc2bN9cZr2/fa3Qz9j97KVpRl66MAZKSkrCzswPurwr422+/GaRO\nY/akjAGWLl3KjBkzDFGeSdCVcU1NDT/99BPDhw8HICYmho4dZRnqhtCVc9OmTWnatCl3795Fo9FQ\nXl6OpaWlIcs1Subm5nz22WePXM+lIX2v0TX2P3spWlGXroyB2vUGbt68ydGjRxk2bNgzr9HYPSnj\npKQkBg4ciL29vSHKMwm6Mi4pKaFly5YsWbIEX19f4uPjDVWm0dOVc7NmzYiMjMTd3R03Nzf69OnD\nSy+9ZKhSjZaZmRnNmzd/5FhD+l6ja+z/TZFv4+ndozIuLi4mPDycmJgYrV9q0TAPZ3zr1i2SkpII\nCgoyYEWm5+GMFUWhoKCAgIAAtmzZQk5ODikpKYYrzoQ8nHNZWRnr1q0jOTmZgwcPcurUKX7++WcD\nViegETZ2WYpW/3RlDPd/WUNDQ5k+fTouLi6GKNHo6co4PT2dkpISJk+ezNSpU8nOzmbx4sWGKtVo\n6cq4bdu2dOzYkU6dOqFWq3F2dubcuXOGKtWo6co5Ly8PR0dHrKysMDc3Z8CAAZw5c8ZQpZqkhvS9\nRtfYZSla/dOVMdy/9hsYGIirq6uhSjR6ujL29PRkz5497Nixg08//ZRevXoxZ84cQ5ZrlHRlbGZm\nhqOjIxcvXqwdl4+IG0ZXzvb29uTl5VFRUQHAmTNn6Ny5s6FKNUkN6XuNcuU5WYpW/x6XsYuLC05O\nTvTt27f2vWPHjsXHx8eA1RonXf+OH7h69SpRUVFs3rzZgJUaL10ZX7p0idmzZ6MoCt26dWP+/Pk0\nadLo5jJGQVfO27dvJykpCbVaTd++fZk1S57EWV9nzpxh2bJl5OfnY2Zmhq2tLcOHD8fBwaFBfa9R\nNnYhhBBCNIycvgohhBAmRBq7EEIIYUKksQshhBAmRBq7EEIIYUKksQshhBAmxMzQBQjxPLh69Sqe\nnp5aXyMEmDNnDj169HjkNgkJCWg0mj+0nnxGRgZTpkyhZ8+eAFRWVtKzZ0+io6Np2rRpvfZ1+PBh\nsrOziYiIIDMzE2traxwdHYmNjWX8+PH07t27wXUmJCSQlJSEg4MDABqNBjs7OxYuXIiFhcVjtyso\nKODChQs4Ozs3+NhCmBpp7EI8I1ZWVgb5vnq3bt1qj6soCjNmzCAxMRE/P7967cfV1bV20aKkpCRG\njx6No6Mj0dHRf0qdb7zxhtZJzIoVK1i7di3vv//+Y7fJyMggLy9PGrsQD5HGLoSB5eXlERMTg1qt\npqysjOnTpzN06NDacY1Gw9y5c/n1119RqVT06NGDmJgYqqqqWLhwIZcuXeLOnTuMHTuW4OBgncdS\nqVT079+fCxcuAJCSksLq1atp3rw5L7zwAosWLcLW1pa4uDjS09MxNzfH1taWZcuWsXv3blJTU3n9\n9ddJTk4mKyuLqKgo1qxZQ0REBPHx8URHR9OvXz8A3nzzTYKCgujatSsLFiygvLycu3fv8t577zF4\n8OAn5tK3b1927NgBwPHjx4mLi8Pc3JyKigpiYmJo3bo1K1euRFEU2rRpw+TJk+udhxCmSBq7EAZW\nVFTEtGnTcHJy4sSJEyxatEirsefm5nLq1Cn27t0LwI4dOygtLSUxMREbGxs+/PBD7t27h7e3N4MH\nD6Z79+6PPVZlZSWHDh3Cy8uL8vJy5s6dy86dO7Gzs2PLli2sXLmS2bNns3XrVo4fP45arWbPnj1a\na1V7eHiwadMmIiIicHZ2Zs2aNQCMGzeOffv20a9fP4qLi8nLy8PFxYWIiAiCg4MZNGgQhYWF+Pj4\nsH//fszMHv/fj0ajYffu3bzyyivA/QfnzJ8/n+7du7N7927WrVvHqlWrmDBhAhqNhqCgID7//PN6\n5yGEKZLGLsQzUlJSgr+/v9Zrn3zyCdbW1ixfvpyPP/6Y6upqbt26pfWeLl260LZtW0JDQ3Fzc2PU\nqFFYWFiQkZHBjRs3OHbsGABVVVVcvny5TiPLzc3VOq6bmxujR4/m7NmztGvXDjs7OwAGDhzI9u3b\nsbS0ZOjQofj5+eHh4cHo0aNr36PLmDFj8PX1JSoqiuTkZDw9PVGr1WRkZHDnzh1Wr14N3F/Hvbi4\nGFtbW63tv/32WzIzM1EUhZycHAICAggLCwOgffv2LF++nMrKSkpLSx/5zO+nzUMIUyeNXYhn5HHX\n2GfOnMmYMWPw8vIiNzeX8PBwrfFmzZrx5Zdfkp2dXTvb3rZtG+bm5kRGRuLp6anzuA9fY3+YSqXS\n+ruiKLWvrVq1iry8PL7//nv8/PxISEh44s/34Ga6rKws9u7dy+zZswEwNzcnISFB65nSj/LwNfbw\n8HDs7e1rZ/WzZs1iwYIFODs7c+jQIdavX19n+6fNQwhTJ193E8LAioqK6Nq1KwB79uyhqqpKa/z0\n6dN888039OrVi6lTp9KrVy8uXrxI//79az+er6mpYcmSJXVm+7p07tyZ4uJirl27BkBaWhp9+vTh\nypUrbNy4kS5duhAcHIyHh0edZ2yrVCqqq6vr7HPcuHHs3LmT27dv194l/3CdJSUlxMbGPrG2mJgY\nEhISuHHjhlZG9+7dIzk5uTYjlUqFRqOpc5yG5CGEqZDGLoSBBQcHM2vWLEJCQujfvz+WlpYsXbq0\ndrxTp07s27ePiRMnEhAQQOvWrenXrx+TJ0+mRYsW+Pj44O3tjYWFBW3atHnq4zZv3pzY2FhmzJiB\nv78/aWlpTJ8+HVtbW3JycvDy8iIwMJD8/HxGjhypte2QIUOIiYlh//79Wq+PHDmSXbt2MWbMmNrX\noqOjOXDgAJMmTSIsLIxBgwY9sbYOHToQGhrKvHnzAAgNDSUwMJDw8HAmTJjA9evX2bhxIwMGDCAp\nKYmVK1f+4TyEMBXydDchhBDChMiMXQghhDAh0tiFEEIIEyKNXQghhDAh0tiFEEIIEyKNXQghhDAh\n0tiFEEIIEyKNXQghhDAh0tiFEEIIE/J/kvnVR8nfcYAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd5fe7c0b10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}